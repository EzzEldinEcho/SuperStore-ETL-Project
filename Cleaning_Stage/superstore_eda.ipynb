{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67d5db8",
   "metadata": {},
   "source": [
    "# Importing Pandas and reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ec2919bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e189c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\Ezz\\ITI Data Engineering\\Data Preparation, Exploration and Visualization\\Project\\Dataset\\Sample - Superstore.csv\" , encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b1cc2f",
   "metadata": {},
   "source": [
    "# Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dfe7638d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>...</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>11/8/2016</td>\n",
       "      <td>11/11/2016</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>261.9600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>11/8/2016</td>\n",
       "      <td>11/11/2016</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>731.9400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.5820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CA-2016-138688</td>\n",
       "      <td>6/12/2016</td>\n",
       "      <td>6/16/2016</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>90036</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "      <td>14.6200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.8714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>10/11/2015</td>\n",
       "      <td>10/18/2015</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-TA-10000577</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Tables</td>\n",
       "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
       "      <td>957.5775</td>\n",
       "      <td>5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-383.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>10/11/2015</td>\n",
       "      <td>10/18/2015</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311</td>\n",
       "      <td>South</td>\n",
       "      <td>OFF-ST-10000760</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Eldon Fold 'N Roll Cart System</td>\n",
       "      <td>22.3680</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.5164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
       "0       1  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
       "1       2  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
       "2       3  CA-2016-138688   6/12/2016   6/16/2016    Second Class    DV-13045   \n",
       "3       4  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
       "4       5  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
       "\n",
       "     Customer Name    Segment        Country             City  ...  \\\n",
       "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
       "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
       "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
       "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
       "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
       "\n",
       "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
       "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
       "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
       "2       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
       "3       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
       "4       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
       "\n",
       "                                        Product Name     Sales  Quantity  \\\n",
       "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
       "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
       "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
       "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
       "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
       "\n",
       "   Discount    Profit  \n",
       "0      0.00   41.9136  \n",
       "1      0.00  219.5820  \n",
       "2      0.00    6.8714  \n",
       "3      0.45 -383.0310  \n",
       "4      0.20    2.5164  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "780ca990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (9994, 21)\n",
      "\n",
      "Columns:\n",
      " ['Row ID', 'Order ID', 'Order Date', 'Ship Date', 'Ship Mode', 'Customer ID', 'Customer Name', 'Segment', 'Country', 'City', 'State', 'Postal Code', 'Region', 'Product ID', 'Category', 'Sub-Category', 'Product Name', 'Sales', 'Quantity', 'Discount', 'Profit']\n",
      "\n",
      "--- Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9994 entries, 0 to 9993\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Row ID         9994 non-null   int64  \n",
      " 1   Order ID       9994 non-null   object \n",
      " 2   Order Date     9994 non-null   object \n",
      " 3   Ship Date      9994 non-null   object \n",
      " 4   Ship Mode      9994 non-null   object \n",
      " 5   Customer ID    9994 non-null   object \n",
      " 6   Customer Name  9994 non-null   object \n",
      " 7   Segment        9994 non-null   object \n",
      " 8   Country        9994 non-null   object \n",
      " 9   City           9994 non-null   object \n",
      " 10  State          9994 non-null   object \n",
      " 11  Postal Code    9994 non-null   int64  \n",
      " 12  Region         9994 non-null   object \n",
      " 13  Product ID     9994 non-null   object \n",
      " 14  Category       9994 non-null   object \n",
      " 15  Sub-Category   9994 non-null   object \n",
      " 16  Product Name   9994 non-null   object \n",
      " 17  Sales          9994 non-null   float64\n",
      " 18  Quantity       9994 non-null   int64  \n",
      " 19  Discount       9994 non-null   float64\n",
      " 20  Profit         9994 non-null   float64\n",
      "dtypes: float64(3), int64(3), object(15)\n",
      "memory usage: 1.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\\n\", df.columns.tolist())\n",
    "print(\"\\n--- Info ---\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f418288",
   "metadata": {},
   "source": [
    "# What to do.\n",
    "### Order Date & Ship Date ---> date\n",
    "### Check for missing values (if any replace or drop)\n",
    "### Check for Duplicates\n",
    "### Check for any inconsistency data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "26507b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of Data for Backup\n",
    "df_backup = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ff982",
   "metadata": {},
   "source": [
    "# Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ad3bbca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row ID           0\n",
       "Order ID         0\n",
       "Order Date       0\n",
       "Ship Date        0\n",
       "Ship Mode        0\n",
       "Customer ID      0\n",
       "Customer Name    0\n",
       "Segment          0\n",
       "Country          0\n",
       "City             0\n",
       "State            0\n",
       "Postal Code      0\n",
       "Region           0\n",
       "Product ID       0\n",
       "Category         0\n",
       "Sub-Category     0\n",
       "Product Name     0\n",
       "Sales            0\n",
       "Quantity         0\n",
       "Discount         0\n",
       "Profit           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how many missing values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "39915ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row ID           0\n",
       "Order ID         0\n",
       "Order Date       0\n",
       "Ship Date        0\n",
       "Ship Mode        0\n",
       "Customer ID      0\n",
       "Customer Name    0\n",
       "Segment          0\n",
       "Country          0\n",
       "City             0\n",
       "State            0\n",
       "Postal Code      0\n",
       "Region           0\n",
       "Product ID       0\n",
       "Category         0\n",
       "Sub-Category     0\n",
       "Product Name     0\n",
       "Sales            0\n",
       "Quantity         0\n",
       "Discount         0\n",
       "Profit           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for empty strings in the dataset\n",
    "(df == \"\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a87048d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA : 0\n",
      "N/A : 0\n",
      "- : 0\n",
      "-- : 0\n",
      "None : 0\n",
      "nan : 0\n"
     ]
    }
   ],
   "source": [
    "# Check for common placeholders for missing data\n",
    "for placeholder in ['NA', 'N/A', '-', '--', 'None', 'nan']:\n",
    "    print(placeholder, \":\", (df == placeholder).sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103f8bd",
   "metadata": {},
   "source": [
    "# Checking for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b13ccc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7150582",
   "metadata": {},
   "source": [
    "# Converting [Order Date , Ship Date] --> date type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a11a20a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/8/2016</td>\n",
       "      <td>11/11/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/8/2016</td>\n",
       "      <td>11/11/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/12/2016</td>\n",
       "      <td>6/16/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/11/2015</td>\n",
       "      <td>10/18/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/11/2015</td>\n",
       "      <td>10/18/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6/9/2014</td>\n",
       "      <td>6/14/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6/9/2014</td>\n",
       "      <td>6/14/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6/9/2014</td>\n",
       "      <td>6/14/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6/9/2014</td>\n",
       "      <td>6/14/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6/9/2014</td>\n",
       "      <td>6/14/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6/9/2014</td>\n",
       "      <td>6/14/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6/9/2014</td>\n",
       "      <td>6/14/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4/15/2017</td>\n",
       "      <td>4/20/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12/5/2016</td>\n",
       "      <td>12/10/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11/22/2015</td>\n",
       "      <td>11/26/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11/22/2015</td>\n",
       "      <td>11/26/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11/11/2014</td>\n",
       "      <td>11/18/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5/13/2014</td>\n",
       "      <td>5/15/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8/27/2014</td>\n",
       "      <td>9/1/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8/27/2014</td>\n",
       "      <td>9/1/2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Order Date   Ship Date\n",
       "0    11/8/2016  11/11/2016\n",
       "1    11/8/2016  11/11/2016\n",
       "2    6/12/2016   6/16/2016\n",
       "3   10/11/2015  10/18/2015\n",
       "4   10/11/2015  10/18/2015\n",
       "5     6/9/2014   6/14/2014\n",
       "6     6/9/2014   6/14/2014\n",
       "7     6/9/2014   6/14/2014\n",
       "8     6/9/2014   6/14/2014\n",
       "9     6/9/2014   6/14/2014\n",
       "10    6/9/2014   6/14/2014\n",
       "11    6/9/2014   6/14/2014\n",
       "12   4/15/2017   4/20/2017\n",
       "13   12/5/2016  12/10/2016\n",
       "14  11/22/2015  11/26/2015\n",
       "15  11/22/2015  11/26/2015\n",
       "16  11/11/2014  11/18/2014\n",
       "17   5/13/2014   5/15/2014\n",
       "18   8/27/2014    9/1/2014\n",
       "19   8/27/2014    9/1/2014"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Order Date and Ship Date columns\n",
    "df[['Order Date','Ship Date']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5f2cb414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2016-11-08\n",
       "1      2016-11-08\n",
       "2      2016-06-12\n",
       "3      2015-10-11\n",
       "4      2015-10-11\n",
       "          ...    \n",
       "9989   2014-01-21\n",
       "9990   2017-02-26\n",
       "9991   2017-02-26\n",
       "9992   2017-02-26\n",
       "9993   2017-05-04\n",
       "Name: Order Date, Length: 9994, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'Order Date' to datetime and confirm it converted without errors\n",
    "pd.to_datetime(df['Order Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a3c97d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2016-11-11\n",
       "1      2016-11-11\n",
       "2      2016-06-16\n",
       "3      2015-10-18\n",
       "4      2015-10-18\n",
       "          ...    \n",
       "9989   2014-01-23\n",
       "9990   2017-03-03\n",
       "9991   2017-03-03\n",
       "9992   2017-03-03\n",
       "9993   2017-05-09\n",
       "Name: Ship Date, Length: 9994, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'Ship Date' to datetime and confirm it converted without errors\n",
    "pd.to_datetime(df['Ship Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8ff47c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Order Date' and 'Ship Date' to datetime\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'])\n",
    "df['Ship Date'] = pd.to_datetime(df['Ship Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "07fe5cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>2016-11-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>2016-11-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>2016-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>2015-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>2015-10-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>2014-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>2014-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>2014-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>2014-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>2014-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>2014-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>2014-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-04-15</td>\n",
       "      <td>2017-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>2016-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-11-22</td>\n",
       "      <td>2015-11-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-11-22</td>\n",
       "      <td>2015-11-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014-11-11</td>\n",
       "      <td>2014-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014-05-13</td>\n",
       "      <td>2014-05-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014-08-27</td>\n",
       "      <td>2014-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014-08-27</td>\n",
       "      <td>2014-09-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order Date  Ship Date\n",
       "0  2016-11-08 2016-11-11\n",
       "1  2016-11-08 2016-11-11\n",
       "2  2016-06-12 2016-06-16\n",
       "3  2015-10-11 2015-10-18\n",
       "4  2015-10-11 2015-10-18\n",
       "5  2014-06-09 2014-06-14\n",
       "6  2014-06-09 2014-06-14\n",
       "7  2014-06-09 2014-06-14\n",
       "8  2014-06-09 2014-06-14\n",
       "9  2014-06-09 2014-06-14\n",
       "10 2014-06-09 2014-06-14\n",
       "11 2014-06-09 2014-06-14\n",
       "12 2017-04-15 2017-04-20\n",
       "13 2016-12-05 2016-12-10\n",
       "14 2015-11-22 2015-11-26\n",
       "15 2015-11-22 2015-11-26\n",
       "16 2014-11-11 2014-11-18\n",
       "17 2014-05-13 2014-05-15\n",
       "18 2014-08-27 2014-09-01\n",
       "19 2014-08-27 2014-09-01"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Order Date and Ship Date columns\n",
    "df[['Order Date','Ship Date']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9620aaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order Date    datetime64[ns]\n",
       "Ship Date     datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data types of the converted columns\n",
    "df[['Order Date','Ship Date']].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fbfdfe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order Date    0\n",
       "Ship Date     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the converted columns\n",
    "df[['Order Date', 'Ship Date']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f00345c",
   "metadata": {},
   "source": [
    "# Checking for consistency in other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b7ed5fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       42420\n",
       "1       42420\n",
       "2       90036\n",
       "3       33311\n",
       "4       33311\n",
       "        ...  \n",
       "9989    33180\n",
       "9990    92627\n",
       "9991    92627\n",
       "9992    92627\n",
       "9993    92683\n",
       "Name: Postal Code, Length: 9994, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Postal Code column\n",
    "df['Postal Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6dc144bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discount anomalies: 0\n",
      "Negative quantity rows: 0\n",
      "Negative sales rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for anomalies in Discount, Quantity, and Sales columns\n",
    "print(\"Discount anomalies:\", df[(df['Discount'] < 0) | (df['Discount'] > 1)].shape[0])\n",
    "print(\"Negative quantity rows:\", (df['Quantity'] < 0).sum())\n",
    "print(\"Negative sales rows:\", (df['Sales'] < 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "edffa572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Order ID', 'Ship Mode', 'Customer ID', 'Customer Name', 'Segment',\n",
       "       'Country', 'City', 'State', 'Region', 'Product ID', 'Category',\n",
       "       'Sub-Category', 'Product Name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all categorical columns\n",
    "df.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f0b2014a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Second Class' 'Standard Class' 'First Class' 'Same Day']\n",
      "['Consumer' 'Corporate' 'Home Office']\n",
      "['Furniture' 'Office Supplies' 'Technology']\n",
      "['Bookcases' 'Chairs' 'Labels' 'Tables' 'Storage' 'Furnishings' 'Art'\n",
      " 'Phones' 'Binders' 'Appliances' 'Paper' 'Accessories' 'Envelopes'\n",
      " 'Fasteners' 'Supplies' 'Machines' 'Copiers']\n",
      "['United States']\n",
      "['South' 'West' 'Central' 'East']\n"
     ]
    }
   ],
   "source": [
    "# Unique values in categorical columns\n",
    "print(df['Ship Mode'].unique())\n",
    "print(df['Segment'].unique())\n",
    "print(df['Category'].unique())\n",
    "print(df['Sub-Category'].unique())\n",
    "print(df['Country'].unique())\n",
    "print(df['Region'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "92859f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kentucky' 'California' 'Florida' 'North Carolina' 'Washington' 'Texas'\n",
      " 'Wisconsin' 'Utah' 'Nebraska' 'Pennsylvania' 'Illinois' 'Minnesota'\n",
      " 'Michigan' 'Delaware' 'Indiana' 'New York' 'Arizona' 'Virginia'\n",
      " 'Tennessee' 'Alabama' 'South Carolina' 'Oregon' 'Colorado' 'Iowa' 'Ohio'\n",
      " 'Missouri' 'Oklahoma' 'New Mexico' 'Louisiana' 'Connecticut' 'New Jersey'\n",
      " 'Massachusetts' 'Georgia' 'Nevada' 'Rhode Island' 'Mississippi'\n",
      " 'Arkansas' 'Montana' 'New Hampshire' 'Maryland' 'District of Columbia'\n",
      " 'Kansas' 'Vermont' 'Maine' 'South Dakota' 'Idaho' 'North Dakota'\n",
      " 'Wyoming' 'West Virginia']\n"
     ]
    }
   ],
   "source": [
    "# Unique states in the 'State' column\n",
    "print(df['State'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "14659bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Henderson' 'Los Angeles' 'Fort Lauderdale' 'Concord' 'Seattle'\n",
      " 'Fort Worth' 'Madison' 'West Jordan' 'San Francisco' 'Fremont'\n",
      " 'Philadelphia' 'Orem' 'Houston' 'Richardson' 'Naperville' 'Melbourne'\n",
      " 'Eagan' 'Westland' 'Dover' 'New Albany' 'New York City' 'Troy' 'Chicago'\n",
      " 'Gilbert' 'Springfield' 'Jackson' 'Memphis' 'Decatur' 'Durham' 'Columbia'\n",
      " 'Rochester' 'Minneapolis' 'Portland' 'Saint Paul' 'Aurora' 'Charlotte'\n",
      " 'Orland Park' 'Urbandale' 'Columbus' 'Bristol' 'Wilmington' 'Bloomington'\n",
      " 'Phoenix' 'Roseville' 'Independence' 'Pasadena' 'Newark' 'Franklin'\n",
      " 'Scottsdale' 'San Jose' 'Edmond' 'Carlsbad' 'San Antonio' 'Monroe'\n",
      " 'Fairfield' 'Grand Prairie' 'Redlands' 'Hamilton' 'Westfield' 'Akron'\n",
      " 'Denver' 'Dallas' 'Whittier' 'Saginaw' 'Medina' 'Dublin' 'Detroit'\n",
      " 'Tampa' 'Santa Clara' 'Lakeville' 'San Diego' 'Brentwood' 'Chapel Hill'\n",
      " 'Morristown' 'Cincinnati' 'Inglewood' 'Tamarac' 'Colorado Springs'\n",
      " 'Belleville' 'Taylor' 'Lakewood' 'Arlington' 'Arvada' 'Hackensack'\n",
      " 'Saint Petersburg' 'Long Beach' 'Hesperia' 'Murfreesboro' 'Layton'\n",
      " 'Austin' 'Lowell' 'Manchester' 'Harlingen' 'Tucson' 'Quincy'\n",
      " 'Pembroke Pines' 'Des Moines' 'Peoria' 'Las Vegas' 'Warwick' 'Miami'\n",
      " 'Huntington Beach' 'Richmond' 'Louisville' 'Lawrence' 'Canton'\n",
      " 'New Rochelle' 'Gastonia' 'Jacksonville' 'Auburn' 'Norman' 'Park Ridge'\n",
      " 'Amarillo' 'Lindenhurst' 'Huntsville' 'Fayetteville' 'Costa Mesa'\n",
      " 'Parker' 'Atlanta' 'Gladstone' 'Great Falls' 'Lakeland' 'Montgomery'\n",
      " 'Mesa' 'Green Bay' 'Anaheim' 'Marysville' 'Salem' 'Laredo' 'Grove City'\n",
      " 'Dearborn' 'Warner Robins' 'Vallejo' 'Mission Viejo' 'Rochester Hills'\n",
      " 'Plainfield' 'Sierra Vista' 'Vancouver' 'Cleveland' 'Tyler' 'Burlington'\n",
      " 'Waynesboro' 'Chester' 'Cary' 'Palm Coast' 'Mount Vernon' 'Hialeah'\n",
      " 'Oceanside' 'Evanston' 'Trenton' 'Cottage Grove' 'Bossier City'\n",
      " 'Lancaster' 'Asheville' 'Lake Elsinore' 'Omaha' 'Edmonds' 'Santa Ana'\n",
      " 'Milwaukee' 'Florence' 'Lorain' 'Linden' 'Salinas' 'New Brunswick'\n",
      " 'Garland' 'Norwich' 'Alexandria' 'Toledo' 'Farmington' 'Riverside'\n",
      " 'Torrance' 'Round Rock' 'Boca Raton' 'Virginia Beach' 'Murrieta'\n",
      " 'Olympia' 'Washington' 'Jefferson City' 'Saint Peters' 'Rockford'\n",
      " 'Brownsville' 'Yonkers' 'Oakland' 'Clinton' 'Encinitas' 'Roswell'\n",
      " 'Jonesboro' 'Antioch' 'Homestead' 'La Porte' 'Lansing' 'Cuyahoga Falls'\n",
      " 'Reno' 'Harrisonburg' 'Escondido' 'Royal Oak' 'Rockville' 'Coral Springs'\n",
      " 'Buffalo' 'Boynton Beach' 'Gulfport' 'Fresno' 'Greenville' 'Macon'\n",
      " 'Cedar Rapids' 'Providence' 'Pueblo' 'Deltona' 'Murray' 'Middletown'\n",
      " 'Freeport' 'Pico Rivera' 'Provo' 'Pleasant Grove' 'Smyrna' 'Parma'\n",
      " 'Mobile' 'New Bedford' 'Irving' 'Vineland' 'Glendale' 'Niagara Falls'\n",
      " 'Thomasville' 'Westminster' 'Coppell' 'Pomona' 'North Las Vegas'\n",
      " 'Allentown' 'Tempe' 'Laguna Niguel' 'Bridgeton' 'Everett' 'Watertown'\n",
      " 'Appleton' 'Bellevue' 'Allen' 'El Paso' 'Grapevine' 'Carrollton' 'Kent'\n",
      " 'Lafayette' 'Tigard' 'Skokie' 'Plano' 'Suffolk' 'Indianapolis' 'Bayonne'\n",
      " 'Greensboro' 'Baltimore' 'Kenosha' 'Olathe' 'Tulsa' 'Redmond' 'Raleigh'\n",
      " 'Muskogee' 'Meriden' 'Bowling Green' 'South Bend' 'Spokane' 'Keller'\n",
      " 'Port Orange' 'Medford' 'Charlottesville' 'Missoula' 'Apopka' 'Reading'\n",
      " 'Broomfield' 'Paterson' 'Oklahoma City' 'Chesapeake' 'Lubbock'\n",
      " 'Johnson City' 'San Bernardino' 'Leominster' 'Bozeman' 'Perth Amboy'\n",
      " 'Ontario' 'Rancho Cucamonga' 'Moorhead' 'Mesquite' 'Stockton'\n",
      " 'Ormond Beach' 'Sunnyvale' 'York' 'College Station' 'Saint Louis'\n",
      " 'Manteca' 'San Angelo' 'Salt Lake City' 'Knoxville' 'Little Rock'\n",
      " 'Lincoln Park' 'Marion' 'Littleton' 'Bangor' 'Southaven' 'New Castle'\n",
      " 'Midland' 'Sioux Falls' 'Fort Collins' 'Clarksville' 'Sacramento'\n",
      " 'Thousand Oaks' 'Malden' 'Holyoke' 'Albuquerque' 'Sparks' 'Coachella'\n",
      " 'Elmhurst' 'Passaic' 'North Charleston' 'Newport News' 'Jamestown'\n",
      " 'Mishawaka' 'La Quinta' 'Tallahassee' 'Nashville' 'Bellingham'\n",
      " 'Woodstock' 'Haltom City' 'Wheeling' 'Summerville' 'Hot Springs'\n",
      " 'Englewood' 'Las Cruces' 'Hoover' 'Frisco' 'Vacaville' 'Waukesha'\n",
      " 'Bakersfield' 'Pompano Beach' 'Corpus Christi' 'Redondo Beach' 'Orlando'\n",
      " 'Orange' 'Lake Charles' 'Highland Park' 'Hempstead' 'Noblesville'\n",
      " 'Apple Valley' 'Mount Pleasant' 'Sterling Heights' 'Eau Claire' 'Pharr'\n",
      " 'Billings' 'Gresham' 'Chattanooga' 'Meridian' 'Bolingbrook' 'Maple Grove'\n",
      " 'Woodland' 'Missouri City' 'Pearland' 'San Mateo' 'Grand Rapids'\n",
      " 'Visalia' 'Overland Park' 'Temecula' 'Yucaipa' 'Revere' 'Conroe'\n",
      " 'Tinley Park' 'Dubuque' 'Dearborn Heights' 'Santa Fe' 'Hickory'\n",
      " 'Carol Stream' 'Saint Cloud' 'North Miami' 'Plantation'\n",
      " 'Port Saint Lucie' 'Rock Hill' 'Odessa' 'West Allis' 'Chula Vista'\n",
      " 'Manhattan' 'Altoona' 'Thornton' 'Champaign' 'Texarkana' 'Edinburg'\n",
      " 'Baytown' 'Greenwood' 'Woonsocket' 'Superior' 'Bedford' 'Covington'\n",
      " 'Broken Arrow' 'Miramar' 'Hollywood' 'Deer Park' 'Wichita' 'Mcallen'\n",
      " 'Iowa City' 'Boise' 'Cranston' 'Port Arthur' 'Citrus Heights'\n",
      " 'The Colony' 'Daytona Beach' 'Bullhead City' 'Portage' 'Fargo' 'Elkhart'\n",
      " 'San Gabriel' 'Margate' 'Sandy Springs' 'Mentor' 'Lawton' 'Hampton'\n",
      " 'Rome' 'La Crosse' 'Lewiston' 'Hattiesburg' 'Danville' 'Logan'\n",
      " 'Waterbury' 'Athens' 'Avondale' 'Marietta' 'Yuma' 'Wausau' 'Pasco'\n",
      " 'Oak Park' 'Pensacola' 'League City' 'Gaithersburg' 'Lehi' 'Tuscaloosa'\n",
      " 'Moreno Valley' 'Georgetown' 'Loveland' 'Chandler' 'Helena' 'Kirkwood'\n",
      " 'Waco' 'Frankfort' 'Bethlehem' 'Grand Island' 'Woodbury' 'Rogers'\n",
      " 'Clovis' 'Jupiter' 'Santa Barbara' 'Cedar Hill' 'Norfolk' 'Draper'\n",
      " 'Ann Arbor' 'La Mesa' 'Pocatello' 'Holland' 'Milford' 'Buffalo Grove'\n",
      " 'Lake Forest' 'Redding' 'Chico' 'Utica' 'Conway' 'Cheyenne' 'Owensboro'\n",
      " 'Caldwell' 'Kenner' 'Nashua' 'Bartlett' 'Redwood City' 'Lebanon'\n",
      " 'Santa Maria' 'Des Plaines' 'Longview' 'Hendersonville' 'Waterloo'\n",
      " 'Cambridge' 'Palatine' 'Beverly' 'Eugene' 'Oxnard' 'Renton' 'Glenview'\n",
      " 'Delray Beach' 'Commerce City' 'Texas City' 'Wilson' 'Rio Rancho'\n",
      " 'Goldsboro' 'Montebello' 'El Cajon' 'Beaumont' 'West Palm Beach'\n",
      " 'Abilene' 'Normal' 'Saint Charles' 'Camarillo' 'Hillsboro' 'Burbank'\n",
      " 'Modesto' 'Garden City' 'Atlantic City' 'Longmont' 'Davis' 'Morgan Hill'\n",
      " 'Clifton' 'Sheboygan' 'East Point' 'Rapid City' 'Andover' 'Kissimmee'\n",
      " 'Shelton' 'Danbury' 'Sanford' 'San Marcos' 'Greeley' 'Mansfield' 'Elyria'\n",
      " 'Twin Falls' 'Coral Gables' 'Romeoville' 'Marlborough' 'Laurel' 'Bryan'\n",
      " 'Pine Bluff' 'Aberdeen' 'Hagerstown' 'East Orange' 'Arlington Heights'\n",
      " 'Oswego' 'Coon Rapids' 'San Clemente' 'San Luis Obispo' 'Springdale'\n",
      " 'Lodi' 'Mason']\n"
     ]
    }
   ],
   "source": [
    "# Unique cities in the 'City' column\n",
    "print(df['City'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "377635e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for leading or trailing spaces in 'State' column\n",
    "df['State'].apply(lambda x: x != x.strip()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ce43e70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State\n",
       "C    2265\n",
       "N    1655\n",
       "T    1168\n",
       "M     726\n",
       "I     692\n",
       "O     659\n",
       "W     621\n",
       "P     587\n",
       "F     383\n",
       "A     345\n",
       "V     235\n",
       "G     184\n",
       "K     163\n",
       "D     106\n",
       "R      56\n",
       "S      54\n",
       "U      53\n",
       "L      42\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count occurrences of states starting with each letter\n",
    "df['State'].str[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4245880a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for leading or trailing spaces in 'City' column\n",
    "df['City'].apply(lambda x: x != x.strip()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "80b80985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City\n",
       "S    1678\n",
       "L    1247\n",
       "N    1118\n",
       "C    1020\n",
       "P     904\n",
       "H     597\n",
       "M     461\n",
       "D     457\n",
       "A     388\n",
       "R     324\n",
       "B     259\n",
       "T     257\n",
       "F     251\n",
       "J     234\n",
       "W     178\n",
       "O     174\n",
       "G     138\n",
       "E     111\n",
       "K      52\n",
       "I      50\n",
       "V      40\n",
       "Y      25\n",
       "Q      20\n",
       "U      11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count occurrences of cities starting with each letter\n",
    "df['City'].str[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbdd9b7",
   "metadata": {},
   "source": [
    "# Checking for non-logical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3cee1d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistent date rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>...</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Row ID, Order ID, Order Date, Ship Date, Ship Mode, Customer ID, Customer Name, Segment, Country, City, State, Postal Code, Region, Product ID, Category, Sub-Category, Product Name, Sales, Quantity, Discount, Profit]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 21 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for inconsistent dates where Ship Date is before Order Date\n",
    "inconsistent_dates = df[df['Ship Date'] < df['Order Date']]\n",
    "print(\"Inconsistent date rows:\", len(inconsistent_dates))\n",
    "inconsistent_dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5052567",
   "metadata": {},
   "source": [
    "# Saving the cleaned data into a new csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a8478d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_clean = df.copy()\n",
    "df_clean.to_csv(\"superstore_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f013e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
